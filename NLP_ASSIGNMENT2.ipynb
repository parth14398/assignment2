{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_ASSIGNMENT2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ0SB2fFsFo_",
        "colab_type": "text"
      },
      "source": [
        "Exploring The Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOP2cPb4sQh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the pandas library to read  dataset\n",
        "import pandas as pd\n",
        "# Get the package from sklearn for preparing  dataset to train and test the model with\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Import the numpy library to work with and manipulate the data\n",
        "import numpy as np\n",
        "#Import the nltk to work with data preprocessing\n",
        "import nltk "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2v58zkxukjt",
        "colab_type": "text"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfqfcyqwufEK",
        "colab_type": "code",
        "outputId": "4672205a-c6bb-4de8-f966-6474f0bf5024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#mount google drive into project\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNNfqT8pwYtH",
        "colab_type": "text"
      },
      "source": [
        "Reading Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFAPjTy-tksm",
        "colab_type": "code",
        "outputId": "66acc4e5-2239-4a9f-d148-473a324802df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "#read the dataset from google drive\n",
        "dataset =  pd.read_csv('/content/drive/My Drive/train.tsv', sep='\\t')\n",
        "dataset = dataset.dropna()\n",
        "#show first 5 rows of the dataset\n",
        "dataset.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBnd7GiNvr7X",
        "colab_type": "code",
        "outputId": "9d941c8e-2491-4e30-9a95-51bf4e366d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "dataset.shape "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK36cXc2vw4A",
        "colab_type": "code",
        "outputId": "676557f9-8b0b-447e-faf1-09f7b4bf0dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#shows the values of each sentiments\n",
        "dataset.Sentiment.value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    79582\n",
              "3    32927\n",
              "1    27273\n",
              "4     9206\n",
              "0     7072\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVUp6R5OxGFK",
        "colab_type": "text"
      },
      "source": [
        "Adjustable Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzyu99V_UvFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#parameters to adjust to see the impact on outcome\n",
        "remove_fPunct = True\n",
        "fTokenizaton = True\n",
        "fStopwords = True\n",
        "fStemming = False\n",
        "fLemmatization = True\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lUk9psizBZk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKtODFJPVEPf",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning | Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXvOmk8F_fyb",
        "colab_type": "code",
        "outputId": "355f2b24-3e70-4e3a-9172-cfb737f3b4d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#print the string punctuation\n",
        "import string\n",
        "print(string.punctuation)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN4KMFgCDAXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove the punctuations\n",
        "import nltk \n",
        "def remove_punctuation(text):\n",
        "  text_nonpunctations = \"\".join([a for a in text if a not in string.punctuation])\n",
        "  return text_nonpunctations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRn28Jk_DYGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if remove_fPunct:\n",
        "  dataset['Phrase'] = dataset['Phrase'].apply(lambda x: remove_punctuation(x)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J_1XQfsFf9G",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning | Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbimWUGpFiOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenization\n",
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "  tokens = re.split('\\W+', text)\n",
        "  return tokens \n",
        "\n",
        "if fTokenizaton:\n",
        "  dataset['Phrase'] = dataset['Phrase'].apply(lambda x: tokenize(x.lower()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxMQGrRuHhse",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihAJokODHp_L",
        "colab_type": "code",
        "outputId": "3177290c-8335-47ae-e73e-59a2ba603d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#remove the stopwords\n",
        "import nltk \n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "stopwords[0:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI3ZmGYJIB9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(txt_tokenized):\n",
        "  txt_clean = [word for word in txt_tokenized if word not in stopwords]\n",
        "  return txt_clean\n",
        "\n",
        "if fStopwords:\n",
        "  dataset['Phrase'] = dataset['Phrase'].apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ibpBZGoKV8V",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning | Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV5IpZ6jKYlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uj82xnvRkuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stemming(tokenized_text):\n",
        "  text = [ps.stem(word) for word in tokenized_text]\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzILzo4UNcYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if fStemming:\n",
        "  dataset['Phrase'] = dataset['Phrase'].apply(lambda x: stemming(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_YooGKsSA8P",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning | Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfcWAnNxSERs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lemmatization\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "def lemmatization(token_txt):\n",
        "  text = [wn.lemmatize(word) for word in token_txt]\n",
        "  return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7NG1Jq8SGzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if fLemmatization:\n",
        "  dataset['Phrase'] = dataset['Phrase'].apply(lambda x: lemmatization(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbNHQyTSWuiv",
        "colab_type": "code",
        "outputId": "0a73c331-d24f-4f93-8ff0-f15de18c37ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[series, escapade, demonstrating, adage, good,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[series, escapade, demonstrating, adage, good,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>[series]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>[series]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>[escapade, demonstrating, adage, good, goose]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>[escapade, demonstrating, adage, good, goose]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>[escapade]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>[demonstrating, adage, good, goose]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          2\n",
              "7         8  ...          2\n",
              "8         9  ...          2\n",
              "9        10  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LblhFFl7eyxd",
        "colab_type": "text"
      },
      "source": [
        "Splitting The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0z-6FIxeyFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs7FpiHciOFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XebxMLR5hBoO",
        "colab_type": "code",
        "outputId": "597eba29-5c9f-4bc4-ae11-4077c13ad59f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "#split the dataset into training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset['Phrase'], dataset['Sentiment'], test_size=0.3, random_state=2003)\n",
        "documents = []\n",
        "X_train = np.array(X_train.values.tolist())\n",
        "Y_train = np.array(Y_train.values.tolist())\n",
        "for i in range(len(X_train)):\n",
        "  documents.append([list(X_train[i]), Y_train[i]]) \n",
        "\n",
        "X_test = np.array(X_test.values.tolist())\n",
        "Y_test = np.array(Y_test.values.tolist())\n",
        "for i in range(len(X_test)):\n",
        "  documents.append([list(X_test[i]), Y_test[i]]) \n",
        "\n",
        "print(documents[0][0])\n",
        "\n",
        "dataset = pd.DataFrame(documents, columns=['text', 'sentiment']) \n",
        "dataset['join'] = dataset.text.apply(' '.join)\n",
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['age']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>join</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[age]</td>\n",
              "      <td>2</td>\n",
              "      <td>age</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[gorgeous, epic]</td>\n",
              "      <td>4</td>\n",
              "      <td>gorgeous epic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[fan, grossout, comedy]</td>\n",
              "      <td>2</td>\n",
              "      <td>fan grossout comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[filmmaker, ascends, literally, olympus, art, ...</td>\n",
              "      <td>4</td>\n",
              "      <td>filmmaker ascends literally olympus art world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[twisting, mystery]</td>\n",
              "      <td>2</td>\n",
              "      <td>twisting mystery</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                           join\n",
              "0                                              [age]  ...                                            age\n",
              "1                                   [gorgeous, epic]  ...                                  gorgeous epic\n",
              "2                            [fan, grossout, comedy]  ...                            fan grossout comedy\n",
              "3  [filmmaker, ascends, literally, olympus, art, ...  ...  filmmaker ascends literally olympus art world\n",
              "4                                [twisting, mystery]  ...                               twisting mystery\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxPION4LRazd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset['join'],  dataset['sentiment'], test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgA0Y2-401nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer \n",
        "from keras.utils import to_categorical\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features = 2500)#, # ngram_range=(1, 1)) \n",
        "X = vectorizer.fit_transform(dataset[\"join\"]) \n",
        "Y = dataset['sentiment'] \n",
        " \n",
        "X_train = vectorizer.transform(X_train).toarray()\n",
        "Y_train = Y_train \n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "Y_test = Y_test\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD4ZenB6Cx-B",
        "colab_type": "code",
        "outputId": "cbc114f9-321a-4375-c215-a5f17889218d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13510     2\n",
              "61932     0\n",
              "82549     1\n",
              "137718    3\n",
              "121990    2\n",
              "         ..\n",
              "94224     2\n",
              "135456    2\n",
              "154729    1\n",
              "23031     1\n",
              "57870     2\n",
              "Name: sentiment, Length: 46818, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFwYA1tWwnhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGCqfGuqSaJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1owiJVMm7Com",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uj80Ku2Socv",
        "colab_type": "code",
        "outputId": "ca506164-dac4-41ca-b9b3-a5aafecaf596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109242, 2500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYgWOcu3S_U2",
        "colab_type": "code",
        "outputId": "dc646325-01b7-484b-bde6-91eca7f6d95e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
        "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
        "Y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BLf_hNSwplF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "#method to count the recall\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "#method to count the precision \n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "#method to count the f1 score\n",
        "def f1(y_true, y_pred):\n",
        "    precision = precision_measure(y_true, y_pred)\n",
        "    recall = recall_measure(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hHjUmvCe_2l",
        "colab_type": "code",
        "outputId": "2cd68986-b91e-412d-bddd-5315c95e21ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "#defining the model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3,\n",
        "                 activation='relu',\n",
        "                 input_shape=(2500,1)))\n",
        "\n",
        "#convolution layer\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#max pooling layer\n",
        "model.add(MaxPooling1D(pool_size=1))\n",
        "\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=1))\n",
        "\n",
        "#dropout layer\n",
        "model.add(Dropout(rate = 0.25))\n",
        "#flattern layer\n",
        "model.add(Flatten())\n",
        "\n",
        "#dence layer\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "#print the model summary for understanding each layer\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_29 (Conv1D)           (None, 2498, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv1d_30 (Conv1D)           (None, 2496, 64)          12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_15 (MaxPooling (None, 2496, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_31 (Conv1D)           (None, 2494, 64)          12352     \n",
            "_________________________________________________________________\n",
            "conv1d_32 (Conv1D)           (None, 2492, 64)          12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling (None, 2492, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2492, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 159488)            0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                1594890   \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 5)                 55        \n",
            "=================================================================\n",
            "Total params: 1,632,257\n",
            "Trainable params: 1,632,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re4qdVOifhJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining the learning rate\n",
        "learning_rate=0.001\n",
        "#defining the optimizer\n",
        "Optimizer=keras.optimizers.Adam(lr=learning_rate)\n",
        "#compile the model\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Optimizer,\n",
        "              metrics=['accuracy',f1,precision,recall])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWnLccEfgKbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaVXITamnrgs",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT8xleC2nc_u",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Acqc_YgZQCYP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RONgsKL5gkqQ",
        "colab_type": "code",
        "outputId": "77e0ea81-c093-43b1-a4a0-f40d0f3dcf3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        }
      },
      "source": [
        "batchsize=64\n",
        "Epochs=25\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=batchsize,\n",
        "          epochs=Epochs)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "109242/109242 [==============================] - 40s 368us/step - loss: 1.1018 - acc: 0.5686 - f1: 0.4992 - precision: 0.6316 - recall: 0.4178\n",
            "Epoch 2/25\n",
            "109242/109242 [==============================] - 39s 356us/step - loss: 1.0011 - acc: 0.5991 - f1: 0.5561 - precision: 0.6664 - recall: 0.4792\n",
            "Epoch 3/25\n",
            "109242/109242 [==============================] - 39s 353us/step - loss: 0.9802 - acc: 0.6062 - f1: 0.5677 - precision: 0.6676 - recall: 0.4957\n",
            "Epoch 4/25\n",
            "109242/109242 [==============================] - 38s 352us/step - loss: 0.9655 - acc: 0.6109 - f1: 0.5754 - precision: 0.6675 - recall: 0.5072\n",
            "Epoch 5/25\n",
            "109242/109242 [==============================] - 39s 353us/step - loss: 0.9559 - acc: 0.6145 - f1: 0.5797 - precision: 0.6674 - recall: 0.5139\n",
            "Epoch 6/25\n",
            "109242/109242 [==============================] - 39s 353us/step - loss: 0.9476 - acc: 0.6164 - f1: 0.5834 - precision: 0.6682 - recall: 0.5193\n",
            "Epoch 7/25\n",
            "109242/109242 [==============================] - 38s 352us/step - loss: 0.9395 - acc: 0.6192 - f1: 0.5857 - precision: 0.6699 - recall: 0.5218\n",
            "Epoch 8/25\n",
            "109242/109242 [==============================] - 38s 351us/step - loss: 0.9343 - acc: 0.6212 - f1: 0.5892 - precision: 0.6704 - recall: 0.5270\n",
            "Epoch 9/25\n",
            "109242/109242 [==============================] - 38s 351us/step - loss: 0.9294 - acc: 0.6231 - f1: 0.5931 - precision: 0.6713 - recall: 0.5325\n",
            "Epoch 10/25\n",
            "109242/109242 [==============================] - 38s 351us/step - loss: 0.9240 - acc: 0.6253 - f1: 0.5943 - precision: 0.6712 - recall: 0.5344\n",
            "Epoch 11/25\n",
            "109242/109242 [==============================] - 38s 350us/step - loss: 0.9188 - acc: 0.6271 - f1: 0.5974 - precision: 0.6730 - recall: 0.5383\n",
            "Epoch 12/25\n",
            "109242/109242 [==============================] - 38s 350us/step - loss: 0.9134 - acc: 0.6287 - f1: 0.6002 - precision: 0.6750 - recall: 0.5414\n",
            "Epoch 13/25\n",
            "109242/109242 [==============================] - 38s 350us/step - loss: 0.9105 - acc: 0.6306 - f1: 0.6006 - precision: 0.6757 - recall: 0.5417\n",
            "Epoch 14/25\n",
            "109242/109242 [==============================] - 38s 352us/step - loss: 0.9072 - acc: 0.6331 - f1: 0.6043 - precision: 0.6775 - recall: 0.5465\n",
            "Epoch 15/25\n",
            "109242/109242 [==============================] - 38s 351us/step - loss: 0.9043 - acc: 0.6337 - f1: 0.6051 - precision: 0.6770 - recall: 0.5481\n",
            "Epoch 16/25\n",
            "109242/109242 [==============================] - 38s 351us/step - loss: 0.8989 - acc: 0.6351 - f1: 0.6075 - precision: 0.6793 - recall: 0.5505\n",
            "Epoch 17/25\n",
            "109242/109242 [==============================] - 39s 356us/step - loss: 0.8957 - acc: 0.6363 - f1: 0.6094 - precision: 0.6792 - recall: 0.5536\n",
            "Epoch 18/25\n",
            "109242/109242 [==============================] - 39s 359us/step - loss: 0.8934 - acc: 0.6382 - f1: 0.6115 - precision: 0.6808 - recall: 0.5561\n",
            "Epoch 19/25\n",
            "109242/109242 [==============================] - 39s 358us/step - loss: 0.8888 - acc: 0.6393 - f1: 0.6130 - precision: 0.6802 - recall: 0.5589\n",
            "Epoch 20/25\n",
            "109242/109242 [==============================] - 39s 357us/step - loss: 0.8868 - acc: 0.6414 - f1: 0.6161 - precision: 0.6815 - recall: 0.5630\n",
            "Epoch 21/25\n",
            "109242/109242 [==============================] - 39s 359us/step - loss: 0.8819 - acc: 0.6434 - f1: 0.6175 - precision: 0.6817 - recall: 0.5653\n",
            "Epoch 22/25\n",
            "109242/109242 [==============================] - 39s 357us/step - loss: 0.8791 - acc: 0.6441 - f1: 0.6196 - precision: 0.6808 - recall: 0.5695\n",
            "Epoch 23/25\n",
            "109242/109242 [==============================] - 39s 357us/step - loss: 0.8769 - acc: 0.6442 - f1: 0.6215 - precision: 0.6812 - recall: 0.5723\n",
            "Epoch 24/25\n",
            "109242/109242 [==============================] - 39s 356us/step - loss: 0.8733 - acc: 0.6460 - f1: 0.6236 - precision: 0.6818 - recall: 0.5753\n",
            "Epoch 25/25\n",
            "109242/109242 [==============================] - 38s 350us/step - loss: 0.8699 - acc: 0.6489 - f1: 0.6269 - precision: 0.6833 - recall: 0.5799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X38J2Okp-r1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v-G7iEQyX3Q",
        "colab_type": "code",
        "outputId": "f15aa670-3ef1-41d0-b3fc-ff33a14be002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print('F1 score:', score[2])\n",
        "print('precision:', score[3])\n",
        "print('recall', score[4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.005148004602503\n",
            "Test accuracy: 0.6132684010423342\n",
            "F1 score: 0.5907722033579055\n",
            "precision: 0.6460010933394291\n",
            "recall 0.545837071211927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VJIB7VEBP-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save the model\n",
        "from keras.models import load_model\n",
        "\n",
        "model.save('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC8L12Z_GlY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}